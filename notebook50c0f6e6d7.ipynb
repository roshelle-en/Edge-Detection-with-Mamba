{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Install basic deps (skip if already done)\n!pip install ninja packaging wheel torch torchvision tqdm opencv-python pillow matplotlib scikit-image einops -q","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:04:23.430443Z","iopub.execute_input":"2025-10-19T11:04:23.430640Z","iopub.status.idle":"2025-10-19T11:05:48.111237Z","shell.execute_reply.started":"2025-10-19T11:04:23.430623Z","shell.execute_reply":"2025-10-19T11:05:48.110397Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m72.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\ngensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.6 which is incompatible.\ngensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.3 which is incompatible.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 2.2.6 which is incompatible.\nnumba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.6 which is incompatible.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nydata-profiling 4.17.0 requires numpy<2.2,>=1.16.0, but you have numpy 2.2.6 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\ntransformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.6 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Stable NumPy/SciPy (no source build needed now)\n!pip install numpy==1.24.3 scipy==1.10.1 --no-cache-dir --force-reinstall -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:06:25.954710Z","iopub.execute_input":"2025-10-19T11:06:25.955298Z","iopub.status.idle":"2025-10-19T11:06:37.521055Z","shell.execute_reply.started":"2025-10-19T11:06:25.955272Z","shell.execute_reply":"2025-10-19T11:06:37.520336Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.9/58.9 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.1/34.1 MB\u001b[0m \u001b[31m56.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\nmkl-umath 0.1.1 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\nmkl-random 1.2.4 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\nmkl-fft 1.3.8 requires numpy<1.27.0,>=1.26.4, but you have numpy 1.24.3 which is incompatible.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\nwoodwork 0.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nfeaturetools 1.31.0 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\nbayesian-optimization 3.1.0 requires numpy>=1.25; python_full_version < \"3.13\", but you have numpy 1.24.3 which is incompatible.\nmne 1.10.1 requires numpy<3,>=1.25, but you have numpy 1.24.3 which is incompatible.\nmne 1.10.1 requires scipy>=1.11, but you have scipy 1.10.1 which is incompatible.\nkaggle-environments 1.18.0 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.24.3 which is incompatible.\ngoogle-colab 1.0.0 requires google-auth==2.38.0, but you have google-auth 2.40.3 which is incompatible.\ngoogle-colab 1.0.0 requires notebook==6.5.7, but you have notebook 6.5.4 which is incompatible.\ngoogle-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\ngoogle-colab 1.0.0 requires requests==2.32.3, but you have requests 2.32.5 which is incompatible.\ngoogle-colab 1.0.0 requires tornado==6.4.2, but you have tornado 6.5.2 which is incompatible.\njax 0.5.2 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\njax 0.5.2 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\ntsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.10.1 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\nopencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\nscikit-image 0.25.2 requires scipy>=1.11.4, but you have scipy 1.10.1 which is incompatible.\ntreescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.24.3 which is incompatible.\nopencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\ncvxpy 1.6.7 requires scipy>=1.11.0, but you have scipy 1.10.1 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\nimbalanced-learn 0.13.0 requires scikit-learn<2,>=1.3.2, but you have scikit-learn 1.2.2 which is incompatible.\nalbumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nxarray-einstats 0.9.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\nxarray-einstats 0.9.1 requires scipy>=1.11, but you have scipy 1.10.1 which is incompatible.\nxarray 2025.7.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\ntransformers 4.53.3 requires huggingface-hub<1.0,>=0.30.0, but you have huggingface-hub 1.0.0rc2 which is incompatible.\nopencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.24.3 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\nalbucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\njaxlib 0.5.1 requires numpy>=1.25, but you have numpy 1.24.3 which is incompatible.\njaxlib 0.5.1 requires scipy>=1.11.1, but you have scipy 1.10.1 which is incompatible.\numap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.2.2 which is incompatible.\npymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\nblosc2 3.6.1 requires numpy>=1.26, but you have numpy 1.24.3 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Manual causal-conv1d install (source build for kernels)\n!wget https://github.com/Dao-AILab/causal-conv1d/archive/refs/tags/v1.1.1.zip\n!unzip v1.1.1.zip\n%cd causal-conv1d-1.1.1\n!pip install . --no-cache-dir\n%cd ..","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:07:24.097216Z","iopub.execute_input":"2025-10-19T11:07:24.097513Z","iopub.status.idle":"2025-10-19T11:09:12.774401Z","shell.execute_reply.started":"2025-10-19T11:07:24.097489Z","shell.execute_reply":"2025-10-19T11:09:12.773494Z"}},"outputs":[{"name":"stdout","text":"--2025-10-19 11:07:24--  https://github.com/Dao-AILab/causal-conv1d/archive/refs/tags/v1.1.1.zip\nResolving github.com (github.com)... 140.82.121.4\nConnecting to github.com (github.com)|140.82.121.4|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://codeload.github.com/Dao-AILab/causal-conv1d/zip/refs/tags/v1.1.1 [following]\n--2025-10-19 11:07:24--  https://codeload.github.com/Dao-AILab/causal-conv1d/zip/refs/tags/v1.1.1\nResolving codeload.github.com (codeload.github.com)... 140.82.121.10\nConnecting to codeload.github.com (codeload.github.com)|140.82.121.10|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [application/zip]\nSaving to: ‘v1.1.1.zip’\n\nv1.1.1.zip              [ <=>                ]  26.63K  --.-KB/s    in 0.007s  \n\n2025-10-19 11:07:24 (3.52 MB/s) - ‘v1.1.1.zip’ saved [27271]\n\nArchive:  v1.1.1.zip\n97711965f6ea028d9fd4fe94e4e490b7c1011e11\n   creating: causal-conv1d-1.1.1/\n   creating: causal-conv1d-1.1.1/.github/\n   creating: causal-conv1d-1.1.1/.github/workflows/\n  inflating: causal-conv1d-1.1.1/.github/workflows/publish.yaml  \n extracting: causal-conv1d-1.1.1/AUTHORS  \n  inflating: causal-conv1d-1.1.1/LICENSE  \n  inflating: causal-conv1d-1.1.1/README.md  \n   creating: causal-conv1d-1.1.1/causal_conv1d/\n  inflating: causal-conv1d-1.1.1/causal_conv1d/__init__.py  \n  inflating: causal-conv1d-1.1.1/causal_conv1d/causal_conv1d_interface.py  \n   creating: causal-conv1d-1.1.1/csrc/\n  inflating: causal-conv1d-1.1.1/csrc/causal_conv1d.cpp  \n  inflating: causal-conv1d-1.1.1/csrc/causal_conv1d.h  \n  inflating: causal-conv1d-1.1.1/csrc/causal_conv1d_bwd.cu  \n  inflating: causal-conv1d-1.1.1/csrc/causal_conv1d_common.h  \n  inflating: causal-conv1d-1.1.1/csrc/causal_conv1d_fwd.cu  \n  inflating: causal-conv1d-1.1.1/csrc/causal_conv1d_update.cu  \n  inflating: causal-conv1d-1.1.1/csrc/static_switch.h  \n  inflating: causal-conv1d-1.1.1/setup.py  \n   creating: causal-conv1d-1.1.1/tests/\n  inflating: causal-conv1d-1.1.1/tests/test_causal_conv1d.py  \n/kaggle/working/causal-conv1d-1.1.1\nProcessing /kaggle/working/causal-conv1d-1.1.1\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from causal_conv1d==1.1.1) (2.6.0+cu124)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from causal_conv1d==1.1.1) (25.0)\nCollecting buildtools (from causal_conv1d==1.1.1)\n  Downloading buildtools-1.0.6.tar.gz (446 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m446.5/446.5 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from causal_conv1d==1.1.1) (1.13.0)\nRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (from buildtools->causal_conv1d==1.1.1) (2.0.41)\nCollecting argparse (from buildtools->causal_conv1d==1.1.1)\n  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\nCollecting twisted (from buildtools->causal_conv1d==1.1.1)\n  Downloading twisted-25.5.0-py3-none-any.whl.metadata (22 kB)\nRequirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from buildtools->causal_conv1d==1.1.1) (3.20.1)\nCollecting furl (from buildtools->causal_conv1d==1.1.1)\n  Downloading furl-2.1.4-py2.py3-none-any.whl.metadata (25 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from buildtools->causal_conv1d==1.1.1) (2.32.5)\nCollecting docopt (from buildtools->causal_conv1d==1.1.1)\n  Downloading docopt-0.6.2.tar.gz (25 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from buildtools->causal_conv1d==1.1.1) (2.9.0.post0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from buildtools->causal_conv1d==1.1.1) (3.1.6)\nCollecting redo (from buildtools->causal_conv1d==1.1.1)\n  Downloading redo-3.0.0-py2.py3-none-any.whl.metadata (8.0 kB)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (3.5)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (2025.9.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->causal_conv1d==1.1.1) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->causal_conv1d==1.1.1) (1.3.0)\nRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from furl->buildtools->causal_conv1d==1.1.1) (1.17.0)\nCollecting orderedmultidict>=1.0.1 (from furl->buildtools->causal_conv1d==1.1.1)\n  Downloading orderedmultidict-1.0.1-py2.py3-none-any.whl.metadata (1.3 kB)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->buildtools->causal_conv1d==1.1.1) (3.0.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->buildtools->causal_conv1d==1.1.1) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->buildtools->causal_conv1d==1.1.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->buildtools->causal_conv1d==1.1.1) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->buildtools->causal_conv1d==1.1.1) (2025.8.3)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy->buildtools->causal_conv1d==1.1.1) (3.2.3)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from twisted->buildtools->causal_conv1d==1.1.1) (25.3.0)\nCollecting automat>=24.8.0 (from twisted->buildtools->causal_conv1d==1.1.1)\n  Downloading automat-25.4.16-py3-none-any.whl.metadata (8.4 kB)\nCollecting constantly>=15.1 (from twisted->buildtools->causal_conv1d==1.1.1)\n  Downloading constantly-23.10.4-py3-none-any.whl.metadata (1.8 kB)\nCollecting hyperlink>=17.1.1 (from twisted->buildtools->causal_conv1d==1.1.1)\n  Downloading hyperlink-21.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\nCollecting incremental>=24.7.0 (from twisted->buildtools->causal_conv1d==1.1.1)\n  Downloading incremental-24.7.2-py3-none-any.whl.metadata (8.1 kB)\nCollecting zope-interface>=5 (from twisted->buildtools->causal_conv1d==1.1.1)\n  Downloading zope_interface-8.0.1-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (44 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m247.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: setuptools>=61.0 in /usr/local/lib/python3.11/dist-packages (from incremental>=24.7.0->twisted->buildtools->causal_conv1d==1.1.1) (75.2.0)\nDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\nDownloading furl-2.1.4-py2.py3-none-any.whl (27 kB)\nDownloading redo-3.0.0-py2.py3-none-any.whl (14 kB)\nDownloading twisted-25.5.0-py3-none-any.whl (3.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m194.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading automat-25.4.16-py3-none-any.whl (42 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m205.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading constantly-23.10.4-py3-none-any.whl (13 kB)\nDownloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/74.6 kB\u001b[0m \u001b[31m262.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading incremental-24.7.2-py3-none-any.whl (20 kB)\nDownloading orderedmultidict-1.0.1-py2.py3-none-any.whl (11 kB)\nDownloading zope_interface-8.0.1-cp311-cp311-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (259 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.8/259.8 kB\u001b[0m \u001b[31m336.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: causal_conv1d, buildtools, docopt\n  Building wheel for causal_conv1d (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for causal_conv1d: filename=causal_conv1d-1.1.1-cp311-cp311-linux_x86_64.whl size=13180150 sha256=54056e2b0b05100988a0b4190bd48b393addcec04c68e547a037360e424cc998\n  Stored in directory: /tmp/pip-ephem-wheel-cache-xo8fe4af/wheels/01/c1/bb/323898257567191a3a7f9b50cf92327d241b55a9501b56f358\n  Building wheel for buildtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for buildtools: filename=buildtools-1.0.6-py3-none-any.whl size=512342 sha256=572fa7ab2adb43c5d14fbf15d8e237a24fc89d1e00544edd4da49bc76fec81fb\n  Stored in directory: /tmp/pip-ephem-wheel-cache-xo8fe4af/wheels/08/ee/fa/4351d8eba6a57dadf762795886f1b5a607311fe493cdc955f4\n  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=0c170283c9ef388dfe77f66529ae09e0f42e35e639c597cfcc2a8a0ab744cc4d\n  Stored in directory: /tmp/pip-ephem-wheel-cache-xo8fe4af/wheels/1a/b0/8c/4b75c4116c31f83c8f9f047231251e13cc74481cca4a78a9ce\nSuccessfully built causal_conv1d buildtools docopt\nInstalling collected packages: redo, docopt, argparse, zope-interface, orderedmultidict, incremental, hyperlink, constantly, automat, twisted, furl, buildtools, causal_conv1d\nSuccessfully installed argparse-1.4.0 automat-25.4.16 buildtools-1.0.6 causal_conv1d-1.1.1 constantly-23.10.4 docopt-0.6.2 furl-2.1.4 hyperlink-21.0.0 incremental-24.7.2 orderedmultidict-1.0.1 redo-3.0.0 twisted-25.5.0 zope-interface-8.0.1\n/kaggle/working\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# Clean previous files/directories\n!rm -rf mamba-1.1.1 causal-conv1d-1.1.1 v1.1.1.zip*\n\n# Re-download and unzip mamba (overwrite mode)\n!wget https://github.com/state-spaces/mamba/archive/refs/tags/v1.1.1.zip\n!unzip -o v1.1.1.zip\n%cd mamba-1.1.1\n!pip install . --no-cache-dir\n%cd ..","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:11:39.189610Z","iopub.execute_input":"2025-10-19T11:11:39.189886Z","iopub.status.idle":"2025-10-19T11:29:09.930063Z","shell.execute_reply.started":"2025-10-19T11:11:39.189861Z","shell.execute_reply":"2025-10-19T11:29:09.929328Z"}},"outputs":[{"name":"stdout","text":"--2025-10-19 11:11:39--  https://github.com/state-spaces/mamba/archive/refs/tags/v1.1.1.zip\nResolving github.com (github.com)... 140.82.121.3\nConnecting to github.com (github.com)|140.82.121.3|:443... connected.\nHTTP request sent, awaiting response... 302 Found\nLocation: https://codeload.github.com/state-spaces/mamba/zip/refs/tags/v1.1.1 [following]\n--2025-10-19 11:11:39--  https://codeload.github.com/state-spaces/mamba/zip/refs/tags/v1.1.1\nResolving codeload.github.com (codeload.github.com)... 140.82.121.9\nConnecting to codeload.github.com (codeload.github.com)|140.82.121.9|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: unspecified [application/zip]\nSaving to: ‘v1.1.1.zip’\n\nv1.1.1.zip              [ <=>                ] 481.93K  --.-KB/s    in 0.04s   \n\n2025-10-19 11:11:39 (12.2 MB/s) - ‘v1.1.1.zip’ saved [493497]\n\nArchive:  v1.1.1.zip\nfb7b5310fa865dbd62aa059b1e26f2b431363e2a\n   creating: mamba-1.1.1/\n   creating: mamba-1.1.1/.github/\n   creating: mamba-1.1.1/.github/workflows/\n  inflating: mamba-1.1.1/.github/workflows/publish.yaml  \n extracting: mamba-1.1.1/.gitignore  \n  inflating: mamba-1.1.1/.gitmodules  \n   creating: mamba-1.1.1/3rdparty/\n   creating: mamba-1.1.1/3rdparty/lm-evaluation-harness/\n extracting: mamba-1.1.1/AUTHORS     \n  inflating: mamba-1.1.1/LICENSE     \n  inflating: mamba-1.1.1/README.md   \n   creating: mamba-1.1.1/assets/\n  inflating: mamba-1.1.1/assets/selection.png  \n   creating: mamba-1.1.1/benchmarks/\n  inflating: mamba-1.1.1/benchmarks/benchmark_generation_mamba_simple.py  \n   creating: mamba-1.1.1/csrc/\n   creating: mamba-1.1.1/csrc/selective_scan/\n  inflating: mamba-1.1.1/csrc/selective_scan/reverse_scan.cuh  \n  inflating: mamba-1.1.1/csrc/selective_scan/selective_scan.cpp  \n  inflating: mamba-1.1.1/csrc/selective_scan/selective_scan.h  \n  inflating: mamba-1.1.1/csrc/selective_scan/selective_scan_bwd_bf16_complex.cu  \n  inflating: mamba-1.1.1/csrc/selective_scan/selective_scan_bwd_bf16_real.cu  \n  inflating: mamba-1.1.1/csrc/selective_scan/selective_scan_bwd_fp16_complex.cu  \n  inflating: mamba-1.1.1/csrc/selective_scan/selective_scan_bwd_fp16_real.cu  \n  inflating: mamba-1.1.1/csrc/selective_scan/selective_scan_bwd_fp32_complex.cu  \n  inflating: mamba-1.1.1/csrc/selective_scan/selective_scan_bwd_fp32_real.cu  \n  inflating: mamba-1.1.1/csrc/selective_scan/selective_scan_bwd_kernel.cuh  \n  inflating: mamba-1.1.1/csrc/selective_scan/selective_scan_common.h  \n  inflating: mamba-1.1.1/csrc/selective_scan/selective_scan_fwd_bf16.cu  \n  inflating: mamba-1.1.1/csrc/selective_scan/selective_scan_fwd_fp16.cu  \n  inflating: mamba-1.1.1/csrc/selective_scan/selective_scan_fwd_fp32.cu  \n  inflating: mamba-1.1.1/csrc/selective_scan/selective_scan_fwd_kernel.cuh  \n  inflating: mamba-1.1.1/csrc/selective_scan/static_switch.h  \n  inflating: mamba-1.1.1/csrc/selective_scan/uninitialized_copy.cuh  \n   creating: mamba-1.1.1/evals/\n  inflating: mamba-1.1.1/evals/lm_harness_eval.py  \n   creating: mamba-1.1.1/mamba_ssm/\n  inflating: mamba-1.1.1/mamba_ssm/__init__.py  \n   creating: mamba-1.1.1/mamba_ssm/models/\n extracting: mamba-1.1.1/mamba_ssm/models/__init__.py  \n  inflating: mamba-1.1.1/mamba_ssm/models/config_mamba.py  \n  inflating: mamba-1.1.1/mamba_ssm/models/mixer_seq_simple.py  \n   creating: mamba-1.1.1/mamba_ssm/modules/\n extracting: mamba-1.1.1/mamba_ssm/modules/__init__.py  \n  inflating: mamba-1.1.1/mamba_ssm/modules/mamba_simple.py  \n   creating: mamba-1.1.1/mamba_ssm/ops/\n extracting: mamba-1.1.1/mamba_ssm/ops/__init__.py  \n  inflating: mamba-1.1.1/mamba_ssm/ops/selective_scan_interface.py  \n   creating: mamba-1.1.1/mamba_ssm/ops/triton/\n extracting: mamba-1.1.1/mamba_ssm/ops/triton/__init__.py  \n  inflating: mamba-1.1.1/mamba_ssm/ops/triton/layernorm.py  \n  inflating: mamba-1.1.1/mamba_ssm/ops/triton/selective_state_update.py  \n   creating: mamba-1.1.1/mamba_ssm/utils/\n extracting: mamba-1.1.1/mamba_ssm/utils/__init__.py  \n  inflating: mamba-1.1.1/mamba_ssm/utils/generation.py  \n  inflating: mamba-1.1.1/mamba_ssm/utils/hf.py  \n  inflating: mamba-1.1.1/setup.py    \n   creating: mamba-1.1.1/tests/\n   creating: mamba-1.1.1/tests/ops/\n  inflating: mamba-1.1.1/tests/ops/test_selective_scan.py  \n   creating: mamba-1.1.1/tests/ops/triton/\n  inflating: mamba-1.1.1/tests/ops/triton/test_selective_state_update.py  \n/kaggle/mamba-1.1.1\nProcessing /kaggle/mamba-1.1.1\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from mamba_ssm==1.1.1) (2.6.0+cu124)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from mamba_ssm==1.1.1) (25.0)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from mamba_ssm==1.1.1) (1.13.0)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from mamba_ssm==1.1.1) (0.8.1)\nRequirement already satisfied: triton in /usr/local/lib/python3.11/dist-packages (from mamba_ssm==1.1.1) (3.2.0)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from mamba_ssm==1.1.1) (4.53.3)\nRequirement already satisfied: causal_conv1d>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from mamba_ssm==1.1.1) (1.1.1)\nRequirement already satisfied: buildtools in /usr/local/lib/python3.11/dist-packages (from causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (1.0.6)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (2025.9.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (12.4.127)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->mamba_ssm==1.1.1) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->mamba_ssm==1.1.1) (1.3.0)\nCollecting huggingface-hub<1.0,>=0.30.0 (from transformers->mamba_ssm==1.1.1)\n  Downloading huggingface_hub-0.35.3-py3-none-any.whl.metadata (14 kB)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba_ssm==1.1.1) (1.24.3)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba_ssm==1.1.1) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba_ssm==1.1.1) (2025.9.18)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers->mamba_ssm==1.1.1) (2.32.5)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba_ssm==1.1.1) (0.21.2)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba_ssm==1.1.1) (0.5.3)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers->mamba_ssm==1.1.1) (4.67.1)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers->mamba_ssm==1.1.1) (1.1.10)\nRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.11/dist-packages (from buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (2.0.41)\nCollecting argparse (from buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1)\n  Downloading argparse-1.4.0-py2.py3-none-any.whl.metadata (2.8 kB)\nRequirement already satisfied: twisted in /usr/local/lib/python3.11/dist-packages (from buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (25.5.0)\nRequirement already satisfied: simplejson in /usr/local/lib/python3.11/dist-packages (from buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (3.20.1)\nRequirement already satisfied: furl in /usr/local/lib/python3.11/dist-packages (from buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (2.1.4)\nRequirement already satisfied: docopt in /usr/local/lib/python3.11/dist-packages (from buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (0.6.2)\nRequirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (2.9.0.post0)\nRequirement already satisfied: redo in /usr/local/lib/python3.11/dist-packages (from buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (3.0.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->mamba_ssm==1.1.1) (3.0.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba_ssm==1.1.1) (3.4.3)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba_ssm==1.1.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba_ssm==1.1.1) (2.5.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers->mamba_ssm==1.1.1) (2025.8.3)\nRequirement already satisfied: six>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from furl->buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (1.17.0)\nRequirement already satisfied: orderedmultidict>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from furl->buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (1.0.1)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy->buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (3.2.3)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from twisted->buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (25.3.0)\nRequirement already satisfied: automat>=24.8.0 in /usr/local/lib/python3.11/dist-packages (from twisted->buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (25.4.16)\nRequirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.11/dist-packages (from twisted->buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (23.10.4)\nRequirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.11/dist-packages (from twisted->buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (21.0.0)\nRequirement already satisfied: incremental>=24.7.0 in /usr/local/lib/python3.11/dist-packages (from twisted->buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (24.7.2)\nRequirement already satisfied: zope-interface>=5 in /usr/local/lib/python3.11/dist-packages (from twisted->buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (8.0.1)\nRequirement already satisfied: setuptools>=61.0 in /usr/local/lib/python3.11/dist-packages (from incremental>=24.7.0->twisted->buildtools->causal_conv1d>=1.1.0->mamba_ssm==1.1.1) (75.2.0)\nDownloading huggingface_hub-0.35.3-py3-none-any.whl (564 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading argparse-1.4.0-py2.py3-none-any.whl (23 kB)\nBuilding wheels for collected packages: mamba_ssm\n  Building wheel for mamba_ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for mamba_ssm: filename=mamba_ssm-1.1.1-cp311-cp311-linux_x86_64.whl size=137484467 sha256=f46ac62f9c0f576605f9b5096af020bcdeb3879c93fcdbad2fdee81a19ebde2d\n  Stored in directory: /tmp/pip-ephem-wheel-cache-ay0n8gzk/wheels/cf/cc/c9/469df86b1a9238ab5e15dd5f5984e1c989ad10c0cec61ae590\nSuccessfully built mamba_ssm\nInstalling collected packages: argparse, huggingface-hub, mamba_ssm\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 1.0.0rc2\n    Uninstalling huggingface-hub-1.0.0rc2:\n      Successfully uninstalled huggingface-hub-1.0.0rc2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 4.1.1 requires pyarrow>=21.0.0, but you have pyarrow 19.0.1 which is incompatible.\ngradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed argparse-1.4.0 huggingface-hub-0.35.3 mamba_ssm-1.1.1\n/kaggle\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# VMamba kernels (selective_scan)\n!git clone https://github.com/MzeroMiko/VMamba.git\n%cd VMamba/kernels/selective_scan\n!pip install . --no-cache-dir\n%cd /kaggle/working  # Back to root","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:30:53.699907Z","iopub.execute_input":"2025-10-19T11:30:53.700663Z","iopub.status.idle":"2025-10-19T11:32:04.685765Z","shell.execute_reply.started":"2025-10-19T11:30:53.700631Z","shell.execute_reply":"2025-10-19T11:32:04.684861Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'VMamba'...\nremote: Enumerating objects: 8910, done.\u001b[K\nremote: Counting objects: 100% (1370/1370), done.\u001b[K\nremote: Compressing objects: 100% (171/171), done.\u001b[K\nremote: Total 8910 (delta 1314), reused 1199 (delta 1199), pack-reused 7540 (from 2)\u001b[K\nReceiving objects: 100% (8910/8910), 34.84 MiB | 39.68 MiB/s, done.\nResolving deltas: 100% (5491/5491), done.\n/kaggle/VMamba/kernels/selective_scan\nProcessing /kaggle/VMamba/kernels/selective_scan\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from selective_scan==0.0.2) (2.6.0+cu124)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from selective_scan==0.0.2) (25.0)\nRequirement already satisfied: ninja in /usr/local/lib/python3.11/dist-packages (from selective_scan==0.0.2) (1.13.0)\nRequirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from selective_scan==0.0.2) (0.8.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (3.19.1)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (4.15.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (2025.9.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->selective_scan==0.0.2) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->selective_scan==0.0.2) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->selective_scan==0.0.2) (3.0.2)\nBuilding wheels for collected packages: selective_scan\n  Building wheel for selective_scan (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for selective_scan: filename=selective_scan-0.0.2-cp311-cp311-linux_x86_64.whl size=9409430 sha256=63401078146c3e4dcc4900e738002c6a6645ca96c762670cf0b448696c822c28\n  Stored in directory: /tmp/pip-ephem-wheel-cache-k7dknety/wheels/81/3d/ad/42e602b9dc214911116e6659ee26dabf6fb85acc9589911d32\nSuccessfully built selective_scan\nInstalling collected packages: selective_scan\nSuccessfully installed selective_scan-0.0.2\n[Errno 2] No such file or directory: '/kaggle/working # Back to root'\n/kaggle/VMamba/kernels/selective_scan\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install pyarrow>=21.0.0 --force-reinstall -q\n!pip install \"pydantic<2.12,>=2.0\" --force-reinstall -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:35:12.421279Z","iopub.execute_input":"2025-10-19T11:35:12.421821Z","iopub.status.idle":"2025-10-19T11:35:39.462890Z","shell.execute_reply.started":"2025-10-19T11:35:12.421796Z","shell.execute_reply":"2025-10-19T11:35:39.462173Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.6/68.6 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m444.8/444.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\nonnx 1.18.0 requires protobuf>=4.25.1, but you have protobuf 3.20.3 which is incompatible.\nkaggle-environments 1.18.0 requires scipy>=1.11.2, but you have scipy 1.10.1 which is incompatible.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\nibis-framework 9.5.0 requires toolz<1,>=0.11, but you have toolz 1.0.0 which is incompatible.\nthinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.24.3 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npydrive2 1.21.3 requires cryptography<44, but you have cryptography 46.0.1 which is incompatible.\npydrive2 1.21.3 requires pyOpenSSL<=24.2.1,>=19.1.0, but you have pyopenssl 25.3.0 which is incompatible.\nalbumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.24.3 which is incompatible.\ntensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\npymc 5.25.1 requires numpy>=1.25.0, but you have numpy 1.24.3 which is incompatible.\ngcsfs 2025.3.0 requires fsspec==2025.3.0, but you have fsspec 2025.9.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Test imports\nimport torch\n\nprint(f\"PyTorch: {torch.__version__}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:41:36.556094Z","iopub.execute_input":"2025-10-19T11:41:36.556379Z","iopub.status.idle":"2025-10-19T11:41:36.560495Z","shell.execute_reply.started":"2025-10-19T11:41:36.556362Z","shell.execute_reply":"2025-10-19T11:41:36.559775Z"}},"outputs":[{"name":"stdout","text":"PyTorch: 2.6.0+cu124\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import mamba_ssm\nprint(f\"Mamba-SSM: {mamba_ssm.__version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:42:04.091438Z","iopub.execute_input":"2025-10-19T11:42:04.092125Z","iopub.status.idle":"2025-10-19T11:42:04.096075Z","shell.execute_reply.started":"2025-10-19T11:42:04.092102Z","shell.execute_reply":"2025-10-19T11:42:04.095252Z"}},"outputs":[{"name":"stdout","text":"Mamba-SSM: 1.1.1\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import scipy\nprint(f\"SciPy: {scipy.__version__}\")\nprint(f\"NumPy: {scipy.__numpy_version__}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:42:58.014527Z","iopub.execute_input":"2025-10-19T11:42:58.015228Z","iopub.status.idle":"2025-10-19T11:42:58.019069Z","shell.execute_reply.started":"2025-10-19T11:42:58.015205Z","shell.execute_reply":"2025-10-19T11:42:58.018230Z"}},"outputs":[{"name":"stdout","text":"SciPy: 1.10.1\nNumPy: 1.26.4\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from causal_conv1d import causal_conv1d_fn  # Correct function name","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:45:59.321846Z","iopub.execute_input":"2025-10-19T11:45:59.322145Z","iopub.status.idle":"2025-10-19T11:45:59.326056Z","shell.execute_reply.started":"2025-10-19T11:45:59.322123Z","shell.execute_reply":"2025-10-19T11:45:59.325251Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"!git clone https://github.com/Li-yachuan/EDMB.git\n%cd EDMB\n!ls -lh # Confirm files like main.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:48:39.604742Z","iopub.execute_input":"2025-10-19T11:48:39.605059Z","iopub.status.idle":"2025-10-19T11:48:40.476343Z","shell.execute_reply.started":"2025-10-19T11:48:39.605022Z","shell.execute_reply":"2025-10-19T11:48:40.475610Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'EDMB'...\nremote: Enumerating objects: 128, done.\u001b[K\nremote: Counting objects: 100% (128/128), done.\u001b[K\nremote: Compressing objects: 100% (126/126), done.\u001b[K\nremote: Total 128 (delta 56), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (128/128), 714.48 KiB | 14.88 MiB/s, done.\nResolving deltas: 100% (56/56), done.\n/kaggle/VMamba/kernels/selective_scan/EDMB\ntotal 84K\n-rw-r--r-- 1 root root  22K Oct 19 11:48 data_process.py\ndrwxr-xr-x 2 root root 4.0K Oct 19 11:48 eval_muge_best\ndrwxr-xr-x 2 root root 4.0K Oct 19 11:48 fig\n-rw-r--r-- 1 root root 1.1K Oct 19 11:48 gflops.py\n-rw-r--r-- 1 root root  12K Oct 19 11:48 main.py\ndrwxr-xr-x 2 root root 4.0K Oct 19 11:48 model\n-rw-r--r-- 1 root root 5.5K Oct 19 11:48 README.md\n-rw-r--r-- 1 root root 2.6K Oct 19 11:48 requirements.txt\n-rw-r--r-- 1 root root  11K Oct 19 11:48 test.py\n-rw-r--r-- 1 root root 3.6K Oct 19 11:48 train.py\n-rw-r--r-- 1 root root 2.5K Oct 19 11:48 utils.py\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"!wget -q --show-progress \"https://github.com/MzeroMiko/VMamba/releases/download/%23v2cls/vssm_small_0229_ckpt_epoch_222.pth\" -O model/vssm_small_0229_ckpt_epoch_222.pth","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:50:32.703817Z","iopub.execute_input":"2025-10-19T11:50:32.704586Z","iopub.status.idle":"2025-10-19T11:50:38.880717Z","shell.execute_reply.started":"2025-10-19T11:50:32.704552Z","shell.execute_reply":"2025-10-19T11:50:38.879973Z"}},"outputs":[{"name":"stdout","text":"model/vssm_small_02 100%[===================>] 191.43M  34.4MB/s    in 5.7s    \n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"!ls -lh model | grep vssm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:52:09.189858Z","iopub.execute_input":"2025-10-19T11:52:09.190185Z","iopub.status.idle":"2025-10-19T11:52:09.332995Z","shell.execute_reply.started":"2025-10-19T11:52:09.190160Z","shell.execute_reply":"2025-10-19T11:52:09.332287Z"}},"outputs":[{"name":"stdout","text":"-rw-r--r-- 1 root root 192M Mar 16  2024 vssm_small_0229_ckpt_epoch_222.pth\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"!pip install -q fvcore","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T11:55:08.935699Z","iopub.execute_input":"2025-10-19T11:55:08.936477Z","iopub.status.idle":"2025-10-19T11:55:16.038246Z","shell.execute_reply.started":"2025-10-19T11:55:08.936452Z","shell.execute_reply":"2025-10-19T11:55:16.037493Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"import os\nos.environ[\"SELECTIVE_SCAN_DEVICE\"] = \"cpu\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T12:00:10.707379Z","iopub.execute_input":"2025-10-19T12:00:10.707877Z","iopub.status.idle":"2025-10-19T12:00:10.711576Z","shell.execute_reply.started":"2025-10-19T12:00:10.707855Z","shell.execute_reply":"2025-10-19T12:00:10.710706Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"\n\n\nimport torch, os\nos.environ[\"SELECTIVE_SCAN_DEVICE\"] = \"cpu\"\nfrom model.vmamba import Backbone_VSSM\n\n# Load pretrained Vision-Mamba backbone\nbackbone = Backbone_VSSM(\n    pretrained=\"model/vssm_small_0229_ckpt_epoch_222.pth\",\n    out_indices=(0, 1, 2),\n    dims=96,\n    depths=(2, 2, 15, 0),\n    ssm_d_state=1,\n    ssm_ratio=2.0,\n    ssm_conv=3,\n    drop_path_rate=0.3,\n)\n\nx = torch.randn(1, 3, 320, 320)\nwith torch.no_grad():\n    feats = backbone(x)\n\nprint(\"✅ Forward pass successful\")\nfor i, f in enumerate(feats):\n    print(f\"  Level {i+1} feature shape:\", tuple(f.shape))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T12:00:56.622018Z","iopub.execute_input":"2025-10-19T12:00:56.622324Z","iopub.status.idle":"2025-10-19T12:00:58.403471Z","shell.execute_reply.started":"2025-10-19T12:00:56.622295Z","shell.execute_reply":"2025-10-19T12:00:58.402092Z"}},"outputs":[{"name":"stdout","text":"Failed loading checkpoint form model/vssm_small_0229_ckpt_epoch_222.pth: Error(s) in loading state_dict for Backbone_VSSM:\n\tsize mismatch for patch_embed.0.weight: copying a param with shape torch.Size([48, 3, 3, 3]) from checkpoint, the shape in current model is torch.Size([96, 3, 4, 4]).\n\tsize mismatch for patch_embed.0.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for patch_embed.2.weight: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for patch_embed.2.bias: copying a param with shape torch.Size([48]) from checkpoint, the shape in current model is torch.Size([96]).\n\tsize mismatch for layers.0.blocks.0.op.in_proj.weight: copying a param with shape torch.Size([192, 96]) from checkpoint, the shape in current model is torch.Size([384, 96]).\n\tsize mismatch for layers.0.blocks.1.op.in_proj.weight: copying a param with shape torch.Size([192, 96]) from checkpoint, the shape in current model is torch.Size([384, 96]).\n\tsize mismatch for layers.0.downsample.1.weight: copying a param with shape torch.Size([192, 96, 3, 3]) from checkpoint, the shape in current model is torch.Size([192, 96, 2, 2]).\n\tsize mismatch for layers.1.blocks.0.op.in_proj.weight: copying a param with shape torch.Size([384, 192]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for layers.1.blocks.1.op.in_proj.weight: copying a param with shape torch.Size([384, 192]) from checkpoint, the shape in current model is torch.Size([768, 192]).\n\tsize mismatch for layers.1.downsample.1.weight: copying a param with shape torch.Size([384, 192, 3, 3]) from checkpoint, the shape in current model is torch.Size([384, 192, 2, 2]).\n\tsize mismatch for layers.2.blocks.0.op.in_proj.weight: copying a param with shape torch.Size([768, 384]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n\tsize mismatch for layers.2.blocks.1.op.in_proj.weight: copying a param with shape torch.Size([768, 384]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n\tsize mismatch for layers.2.blocks.2.op.in_proj.weight: copying a param with shape torch.Size([768, 384]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n\tsize mismatch for layers.2.blocks.3.op.in_proj.weight: copying a param with shape torch.Size([768, 384]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n\tsize mismatch for layers.2.blocks.4.op.in_proj.weight: copying a param with shape torch.Size([768, 384]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n\tsize mismatch for layers.2.blocks.5.op.in_proj.weight: copying a param with shape torch.Size([768, 384]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n\tsize mismatch for layers.2.blocks.6.op.in_proj.weight: copying a param with shape torch.Size([768, 384]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n\tsize mismatch for layers.2.blocks.7.op.in_proj.weight: copying a param with shape torch.Size([768, 384]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n\tsize mismatch for layers.2.blocks.8.op.in_proj.weight: copying a param with shape torch.Size([768, 384]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n\tsize mismatch for layers.2.blocks.9.op.in_proj.weight: copying a param with shape torch.Size([768, 384]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n\tsize mismatch for layers.2.blocks.10.op.in_proj.weight: copying a param with shape torch.Size([768, 384]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n\tsize mismatch for layers.2.blocks.11.op.in_proj.weight: copying a param with shape torch.Size([768, 384]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n\tsize mismatch for layers.2.blocks.12.op.in_proj.weight: copying a param with shape torch.Size([768, 384]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n\tsize mismatch for layers.2.blocks.13.op.in_proj.weight: copying a param with shape torch.Size([768, 384]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n\tsize mismatch for layers.2.blocks.14.op.in_proj.weight: copying a param with shape torch.Size([768, 384]) from checkpoint, the shape in current model is torch.Size([1536, 384]).\n\tsize mismatch for layers.2.downsample.1.weight: copying a param with shape torch.Size([768, 384, 3, 3]) from checkpoint, the shape in current model is torch.Size([768, 384, 2, 2]).\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_37/2325809792.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mfeats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackbone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"✅ Forward pass successful\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/VMamba/kernels/selective_scan/EDMB/model/vmamba.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m   1512\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m             \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (B, H, W, C)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_indices\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m                 \u001b[0mnorm_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'outnorm{i}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/VMamba/kernels/selective_scan/EDMB/model/vmamba.py\u001b[0m in \u001b[0;36mlayer_forward\u001b[0;34m(l, x)\u001b[0m\n\u001b[1;32m   1505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1506\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mlayer_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1507\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1508\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/VMamba/kernels/selective_scan/EDMB/model/vmamba.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1127\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/VMamba/kernels/selective_scan/EDMB/model/vmamba.py\u001b[0m in \u001b[0;36m_forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m   1115\u001b[0m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1117\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmlp_branch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_norm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/VMamba/kernels/selective_scan/EDMB/model/vmamba.py\u001b[0m in \u001b[0;36mforwardv2\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (b, d, h, w)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 717\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_core\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    718\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout_act\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable_z\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/VMamba/kernels/selective_scan/EDMB/model/vmamba.py\u001b[0m in \u001b[0;36mforward_corev2\u001b[0;34m(self, x, to_dtype, force_fp32, ssoflex, SelectiveScan, CrossScan, CrossMerge, no_einsum, cascade2d, **kwargs)\u001b[0m\n\u001b[1;32m    684\u001b[0m                 \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_fp32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m             ys: torch.Tensor = selective_scan(\n\u001b[0m\u001b[1;32m    687\u001b[0m                 \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_softplus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m             ).view(B, K, -1, H, W)\n","\u001b[0;32m/kaggle/VMamba/kernels/selective_scan/EDMB/model/vmamba.py\u001b[0m in \u001b[0;36mselective_scan\u001b[0;34m(u, delta, A, B, C, D, delta_bias, delta_softplus)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mselective_scan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_softplus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mSelectiveScan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_softplus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssoflex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcascade2d\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m             \u001b[0;31m# See NOTE: [functorch vjp and autograd interaction]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_functorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap_dead_wrappers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_setup_ctx_defined\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/amp/autocast_mode.py\u001b[0m in \u001b[0;36mdecorate_fwd\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    501\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcast_inputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fwd_used_autocast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_autocast_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 503\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    504\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0mautocast_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_autocast_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/kaggle/VMamba/kernels/selective_scan/EDMB/model/csms6s.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, u, delta, A, B, C, D, delta_bias, delta_softplus, nrows, backnrows, oflex)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_bias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_softplus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbacknrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moflex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelta_softplus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdelta_softplus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselective_scan_cuda_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_softplus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta_bias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'selective_scan_cuda_core' is not defined"],"ename":"NameError","evalue":"name 'selective_scan_cuda_core' is not defined","output_type":"error"}],"execution_count":23},{"cell_type":"code","source":"!python main.py --batch_size 4 --stepsize \"10-16\" --maxepoch 20 --gpu 0 --encoder DUL-Mamba-s --savedir /kaggle/working/checkpoints --dataset BSDS-rand","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T12:08:02.575982Z","iopub.execute_input":"2025-10-19T12:08:02.576763Z","iopub.status.idle":"2025-10-19T12:08:09.562877Z","shell.execute_reply.started":"2025-10-19T12:08:02.576736Z","shell.execute_reply":"2025-10-19T12:08:09.562173Z"}},"outputs":[{"name":"stdout","text":"[10, 16]\n/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n/usr/local/lib/python3.11/dist-packages/mamba_ssm/ops/selective_scan_interface.py:158: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  @custom_fwd\n/usr/local/lib/python3.11/dist-packages/mamba_ssm/ops/selective_scan_interface.py:231: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  @custom_bwd\n/usr/local/lib/python3.11/dist-packages/mamba_ssm/ops/triton/layernorm.py:507: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n  @custom_fwd\n/usr/local/lib/python3.11/dist-packages/mamba_ssm/ops/triton/layernorm.py:566: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n  @custom_bwd\npython main.py --batch_size 4 --stepsize 10-16 --maxepoch 20 --gpu 0 --encoder DUL-Mamba-s --savedir /kaggle/working/checkpoints --dataset BSDS-rand\nNamespace(batch_size=4, LR=0.0001, weight_decay=0.0005, stepsize=[10, 16], maxepoch=20, start_epoch=0, print_freq=500, gpu='0', loss_lmbda=None, itersize=1, encoder='DUL-Mamba-s', enh='None', decoder='unetp', savedir='/kaggle/working/checkpoints', pretrainlr=0.1, mode='train', resume=None, dataset='BSDS-rand', note=None, multi_gran=False, global_ckpt=None)\nThreshold for ground truth: 0.300000 on BSDS\nTraceback (most recent call last):\n  File \"/kaggle/VMamba/kernels/selective_scan/EDMB/main.py\", line 247, in <module>\n    main()\n  File \"/kaggle/VMamba/kernels/selective_scan/EDMB/main.py\", line 75, in main\n    train_dataset = BSDS_Loader(root=datadir, split=\"train\",label_type=\"rand\")\n                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/kaggle/VMamba/kernels/selective_scan/EDMB/data_process.py\", line 259, in __init__\n    with open(self.filelist, 'r') as f:\n         ^^^^^^^^^^^^^^^^^^^^^^^^\nFileNotFoundError: [Errno 2] No such file or directory: '/data/users/liyachuan/dataset/BSDS-yc/train_BSDS.lst'\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"!cd /kaggle/VMamba/kernels/selective_scan/EDMB","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T12:14:33.473566Z","iopub.execute_input":"2025-10-19T12:14:33.474382Z","iopub.status.idle":"2025-10-19T12:14:33.628706Z","shell.execute_reply.started":"2025-10-19T12:14:33.474352Z","shell.execute_reply":"2025-10-19T12:14:33.627878Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"!ls\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T12:13:46.105751Z","iopub.execute_input":"2025-10-19T12:13:46.106754Z","iopub.status.idle":"2025-10-19T12:13:46.262479Z","shell.execute_reply.started":"2025-10-19T12:13:46.106714Z","shell.execute_reply":"2025-10-19T12:13:46.261718Z"}},"outputs":[{"name":"stdout","text":"data_process.py  fig\t    main.py  __pycache__  requirements.txt  train.py\neval_muge_best\t gflops.py  model    README.md\t  test.py\t    utils.py\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"!mkdir -p data/BSDS500 data/NYUDv2 data/BIPED","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T12:19:25.883232Z","iopub.execute_input":"2025-10-19T12:19:25.883497Z","iopub.status.idle":"2025-10-19T12:19:26.046444Z","shell.execute_reply.started":"2025-10-19T12:19:25.883476Z","shell.execute_reply":"2025-10-19T12:19:26.045406Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"import os\nimport shutil\nimport numpy as np\nfrom PIL import Image\nimport scipy.io as sio\n\n# Clean previous attempt\n!rm -rf data/BSDS500\n\n# Create base dir\nos.makedirs('data/BSDS500', exist_ok=True)\n\n# Download (you already did, but re for completeness)\n!wget https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz -O data/BSDS500/BSR_bsds500.tgz\n\n# Extract\n!tar -xzf data/BSDS500/BSR_bsds500.tgz -C data/BSDS500/\n\n# Debug: List top-level after extraction\n!ls -la data/BSDS500/\n\n# Rename BSR to raw (if it exists)\n!mv data/BSDS500/BSR data/BSDS500_raw 2>/dev/null || echo \"No BSR dir, checking structure\"\n\n# Debug: List raw contents\n!ls -la data/BSDS500_raw/\n!ls -la data/BSDS500_raw/images/ 2>/dev/null || echo \"No images dir\"\n!ls -la data/BSDS500_raw/human/ 2>/dev/null || echo \"No human dir\"\n!ls -la data/BSDS500_raw/groundTruth/test/ 2>/dev/null || echo \"No groundTruth/test dir\"\n\n# Create target subdirs\nos.makedirs('data/BSDS500/images/train', exist_ok=True)\nos.makedirs('data/BSDS500/images/val', exist_ok=True)\nos.makedirs('data/BSDS500/images/test', exist_ok=True)\nos.makedirs('data/BSDS500/groundTruth/train', exist_ok=True)\nos.makedirs('data/BSDS500/groundTruth/val', exist_ok=True)\nos.makedirs('data/BSDS500/groundTruth/test', exist_ok=True)\n\n# Move images (use -n to no-clobber, and check if dir exists)\n!find data/BSDS500_raw -name \"*.jpg\" -path \"*train*\" -exec mv {} data/BSDS500/images/train/ \\; 2>/dev/null || echo \"No train jpgs\"\n!find data/BSDS500_raw -name \"*.jpg\" -path \"*val*\" -exec mv {} data/BSDS500/images/val/ \\; 2>/dev/null || echo \"No val jpgs\"\n!find data/BSDS500_raw -name \"*.jpg\" -path \"*test*\" -exec mv {} data/BSDS500/images/test/ \\; 2>/dev/null || echo \"No test jpgs\"\n\n# Move human GT MATs to train\n!find data/BSDS500_raw -name \"*.mat\" -path \"*human*\" -exec mv {} data/BSDS500/groundTruth/train/ \\; 2>/dev/null || echo \"No human mats\"\n\n# Move test GT MATs\n!find data/BSDS500_raw -name \"*.mat\" -path \"*groundTruth/test*\" -exec mv {} data/BSDS500/groundTruth/test/ \\; 2>/dev/null || echo \"No test mats\"\n\n# Split train GT MATs (all human to train, then split 100 to val)\ntrain_gt_files = [f for f in os.listdir('data/BSDS500/groundTruth/train') if f.endswith('.mat')]\ntrain_gt_files = sorted(train_gt_files)\nval_gt_files = train_gt_files[:100]\ntrain_gt_files = train_gt_files[100:]\n\nfor f in val_gt_files:\n    shutil.move(f'data/BSDS500/groundTruth/train/{f}', f'data/BSDS500/groundTruth/val/{f}')\n\n# Debug counts\nprint(f\"Train images: {len([f for f in os.listdir('data/BSDS500/images/train') if f.endswith('.jpg')])}\")\nprint(f\"Val images: {len([f for f in os.listdir('data/BSDS500/images/val') if f.endswith('.jpg')])}\")\nprint(f\"Test images: {len([f for f in os.listdir('data/BSDS500/images/test') if f.endswith('.jpg')])}\")\nprint(f\"Train GT MATs: {len(train_gt_files)}\")\nprint(f\"Val GT MATs: {len(val_gt_files)}\")\nprint(f\"Test GT MATs: {len([f for f in os.listdir('data/BSDS500/groundTruth/test') if f.endswith('.mat')])}\")\n\n# Optional: Verify one MAT\nif len(train_gt_files) > 0:\n    sample_path = f'data/BSDS500/groundTruth/train/{train_gt_files[0]}'\n    sample_mat = sio.loadmat(sample_path)\n    print(f\"Sample GT loaded: keys = {list(sample_mat.keys())}\")\n\n# Clean up\n!rm -rf data/BSDS500_raw data/BSDS500/*.tgz\n\nprint(\"✅ BSDS500 formatted! Run the test loader cell next.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-19T12:34:57.950442Z","iopub.execute_input":"2025-10-19T12:34:57.950824Z","iopub.status.idle":"2025-10-19T12:35:07.708957Z","shell.execute_reply.started":"2025-10-19T12:34:57.950796Z","shell.execute_reply":"2025-10-19T12:35:07.708108Z"}},"outputs":[{"name":"stdout","text":"--2025-10-19 12:34:58--  https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz\nResolving www2.eecs.berkeley.edu (www2.eecs.berkeley.edu)... 128.32.244.190\nConnecting to www2.eecs.berkeley.edu (www2.eecs.berkeley.edu)|128.32.244.190|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 70763455 (67M) [application/x-tar]\nSaving to: ‘data/BSDS500/BSR_bsds500.tgz’\n\ndata/BSDS500/BSR_bs 100%[===================>]  67.48M  21.7MB/s    in 4.0s    \n\n2025-10-19 12:35:03 (17.0 MB/s) - ‘data/BSDS500/BSR_bsds500.tgz’ saved [70763455/70763455]\n\ntotal 69120\ndrwxr-xr-x 3 root root     4096 Oct 19 12:35 .\ndrwxr-xr-x 5 root root     4096 Oct 19 12:34 ..\ndrwxrwxr-x 5 1000 1000     4096 Jan 22  2013 BSR\n-rw-r--r-- 1 root root 70763455 Jan 22  2013 BSR_bsds500.tgz\ntotal 20\ndrwxrwxr-x 5 1000 1000 4096 Jan 22  2013 .\ndrwxr-xr-x 6 root root 4096 Oct 19 12:35 ..\ndrwxr-xr-x 5 1000 1000 4096 Jan 22  2013 bench\ndrwxr-xr-x 3 1000 1000 4096 Jan 22  2013 BSDS500\ndrwxr-xr-x 2 1000 1000 4096 Jan 22  2013 documentation\nNo images dir\nNo human dir\nNo groundTruth/test dir\nTrain images: 200\nVal images: 100\nTest images: 200\nTrain GT MATs: 0\nVal GT MATs: 0\nTest GT MATs: 200\n✅ BSDS500 formatted! Run the test loader cell next.\n","output_type":"stream"}],"execution_count":36}]}